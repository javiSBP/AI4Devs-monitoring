# LTI - Sistema de Seguimiento de Talento

Este proyecto es una aplicaci√≥n full-stack con un frontend en React y un backend en Express usando Prisma como un ORM. El frontend se inicia con Create React App y el backend est√° escrito en TypeScript.

## Explicaci√≥n de Directorios y Archivos

- `backend/`: Contiene el c√≥digo del lado del servidor escrito en Node.js.
  - `src/`: Contiene el c√≥digo fuente para el backend.
    - `index.ts`: El punto de entrada para el servidor backend.
    - `application/`: Contiene la l√≥gica de aplicaci√≥n.
    - `domain/`: Contiene la l√≥gica de negocio.
    - `infrastructure/`: Contiene c√≥digo que se comunica con la base de datos.
    - `presentation/`: Contiene c√≥digo relacionado con la capa de presentaci√≥n (como controladores).
    - `routes/`: Contiene las definiciones de rutas para la API.
    - `tests/`: Contiene archivos de prueba.
  - `prisma/`: Contiene el archivo de esquema de Prisma para ORM.
  - `tsconfig.json`: Archivo de configuraci√≥n de TypeScript.
- `frontend/`: Contiene el c√≥digo del lado del cliente escrito en React.
  - `src/`: Contiene el c√≥digo fuente para el frontend.
  - `public/`: Contiene archivos est√°ticos como el archivo HTML e im√°genes.
  - `build/`: Contiene la construcci√≥n lista para producci√≥n del frontend.
- `tf/`: Contiene la infraestructura como c√≥digo usando Terraform.
  - `variables.tf`: Variables de configuraci√≥n para Terraform y Datadog.
  - `provider.tf`: Configuraci√≥n de proveedores (AWS, Datadog).
  - `ec2.tf`: Configuraci√≥n de instancias EC2.
  - `datadog.tf`: Configuraci√≥n de monitorizaci√≥n con Datadog.
  - `scripts/`: Scripts de inicializaci√≥n para instancias EC2.
- `.env`: Contiene las variables de entorno.
- `docker-compose.yml`: Contiene la configuraci√≥n de Docker Compose para gestionar los servicios de tu aplicaci√≥n.
- `README.md`: Este archivo, contiene informaci√≥n sobre el proyecto e instrucciones sobre c√≥mo ejecutarlo.

## Estructura del Proyecto

El proyecto est√° dividido en dos directorios principales: `frontend` y `backend`.

### Frontend

El frontend es una aplicaci√≥n React y sus archivos principales est√°n ubicados en el directorio `src`. El directorio `public` contiene activos est√°ticos y el directorio `build` contiene la construcci√≥n de producci√≥n de la aplicaci√≥n.

### Backend

El backend es una aplicaci√≥n Express escrita en TypeScript. El directorio `src` contiene el c√≥digo fuente, dividido en varios subdirectorios:

- `application`: Contiene la l√≥gica de aplicaci√≥n.
- `domain`: Contiene los modelos de dominio.
- `infrastructure`: Contiene c√≥digo relacionado con la infraestructura.
- `presentation`: Contiene c√≥digo relacionado con la capa de presentaci√≥n.
- `routes`: Contiene las rutas de la aplicaci√≥n.
- `tests`: Contiene las pruebas de la aplicaci√≥n.

El directorio `prisma` contiene el esquema de Prisma.

Tienes m√°s informaci√≥n sobre buenas pr√°cticas utilizadas en la [gu√≠a de buenas pr√°cticas](./backend/ManifestoBuenasPracticas.md).

Las especificaciones de todos los endpoints de API los tienes en [api-spec.yaml](./backend/api-spec.yaml).

La descripci√≥n y diagrama del modelo de datos los tienes en [ModeloDatos.md](./backend/ModeloDatos.md).

## Primeros Pasos

Para comenzar con este proyecto, sigue estos pasos:

1. Clona el repositorio.
2. Instala las dependencias para el frontend y el backend:

```sh
cd frontend
npm install

cd ../backend
npm install
```

3. Construye el servidor backend:

```
cd backend
npm run build
```

4. Inicia el servidor backend:

```
cd backend
npm start
```

5. En una nueva ventana de terminal, construye el servidor frontend:

```
cd frontend
npm run build
```

6. Inicia el servidor frontend:

```
cd frontend
npm start
```

El servidor backend estar√° corriendo en http://localhost:3010 y el frontend estar√° disponible en http://localhost:3000.

## Docker y PostgreSQL

Este proyecto usa Docker para ejecutar una base de datos PostgreSQL. As√≠ es c√≥mo ponerlo en marcha:

Instala Docker en tu m√°quina si a√∫n no lo has hecho. Puedes descargarlo desde aqu√≠.
Navega al directorio ra√≠z del proyecto en tu terminal.
Ejecuta el siguiente comando para iniciar el contenedor Docker:

```
docker-compose up -d
```

Esto iniciar√° una base de datos PostgreSQL en un contenedor Docker. La bandera -d corre el contenedor en modo separado, lo que significa que se ejecuta en segundo plano.

Para acceder a la base de datos PostgreSQL, puedes usar cualquier cliente PostgreSQL con los siguientes detalles de conexi√≥n:

- Host: localhost
- Port: 5432
- User: postgres
- Password: password
- Database: mydatabase

Por favor, reemplaza User, Password y Database con el usuario, la contrase√±a y el nombre de la base de datos reales especificados en tu archivo .env.

Para detener el contenedor Docker, ejecuta el siguiente comando:

```
docker-compose down
```

Para generar la base de datos utilizando Prisma, sigue estos pasos:

1. Aseg√∫rate de que el archivo `.env` en el directorio ra√≠z del backend contenga la variable `DATABASE_URL` con la cadena de conexi√≥n correcta a tu base de datos PostgreSQL. Si no te funciona, prueba a reemplazar la URL completa directamente en `schema.prisma`, en la variable `url`.

2. Abre una terminal y navega al directorio del backend donde se encuentra el archivo `schema.prisma` y `seed.ts`.

3. Ejecuta los siguientes comandos para generar la estructura de prisma, las migraciones a tu base de datos y poblarla con datos de ejemplo:

```
npx prisma generate
npx prisma migrate dev
ts-node seed.ts
```

Una vez has dado todos los pasos, deber√≠as poder guardar nuevos candidatos, tanto via web, como via API, verlos en la base de datos y obtenerlos mediante GET por id.

```
POST http://localhost:3010/candidates
{
    "firstName": "Albert",
    "lastName": "Saelices",
    "email": "albert.saelices@gmail.com",
    "phone": "656874937",
    "address": "Calle Sant Dalmir 2, 5¬∫B. Barcelona",
    "educations": [
        {
            "institution": "UC3M",
            "title": "Computer Science",
            "startDate": "2006-12-31",
            "endDate": "2010-12-26"
        }
    ],
    "workExperiences": [
        {
            "company": "Coca Cola",
            "position": "SWE",
            "description": "",
            "startDate": "2011-01-13",
            "endDate": "2013-01-17"
        }
    ],
    "cv": {
        "filePath": "uploads/1715760936750-cv.pdf",
        "fileType": "application/pdf"
    }
}
```

---

## üìä Monitorizaci√≥n con Datadog

Este proyecto incluye integraci√≥n completa con Datadog para monitorizaci√≥n de infraestructura y aplicaciones desplegadas en AWS usando Terraform.

### ‚úÖ Estado de Implementaci√≥n

- **Paso 1 ‚úÖ**: Configuraci√≥n de Variables Terraform para Datadog
- **Paso 2 ‚úÖ**: Configuraci√≥n del Proveedor Datadog
- **Paso 3 ‚úÖ**: Integraci√≥n AWS-Datadog (Roles IAM, Pol√≠ticas, Dashboard)

### Arquitectura de Monitorizaci√≥n

La soluci√≥n de monitorizaci√≥n implementa:

- **Integraci√≥n AWS-Datadog** para m√©tricas de CloudWatch
- **Agentes Datadog** instalados en instancias EC2 (backend y frontend)
- **Dashboard personalizado** para visualizaci√≥n del Sistema LTI
- **Alertas configurables** basadas en umbrales espec√≠ficos del proyecto
- **Recolecci√≥n de logs** de aplicaciones Node.js y React

### Configuraci√≥n de Datadog

#### Archivos de Configuraci√≥n

1. **`tf/variables.tf`** - Variables principales para Datadog:

   - Credenciales de API (marcadas como sensibles)
   - Configuraci√≥n del agente Datadog
   - Umbrales de monitorizaci√≥n espec√≠ficos para LTI
   - Tags organizados por servicio (backend/frontend)

2. **`tf/terraform.tfvars.example`** - Plantilla de configuraci√≥n segura:

   - Ejemplo de configuraci√≥n de credenciales
   - Valores recomendados para el proyecto LTI
   - Documentaci√≥n sobre d√≥nde obtener API keys

3. **`.gitignore`** - Seguridad de credenciales:
   - Exclusi√≥n de archivos `terraform.tfvars` con credenciales reales
   - Protecci√≥n de estados de Terraform sensibles

#### Caracter√≠sticas de Seguridad Implementadas

- **Variables Sensibles**: `datadog_api_key` y `datadog_app_key` marcadas como `sensitive = true`
- **Validaciones**: Verificaci√≥n de que las API keys no est√©n vac√≠as
- **Exclusiones Git**: Archivos con credenciales excluidos del control de versiones
- **External ID**: Configuraci√≥n para role seguro AWS-Datadog

#### Variables Principales Configuradas

```hcl
# Credenciales (obligatorias)
datadog_api_key                # API Key de Datadog
datadog_app_key               # Application Key de Datadog

# Configuraci√≥n del agente
datadog_agent_version         # Versi√≥n del agente (default: "latest")
datadog_enable_logs          # Habilitar logs (default: true)
datadog_enable_apm           # Habilitar APM (default: true)

# Umbrales de alerta para LTI
cpu_threshold_warning        # CPU warning (default: 70%)
cpu_threshold_critical       # CPU cr√≠tico (default: 85%)
memory_threshold_warning     # Memoria warning (default: 80%)
memory_threshold_critical    # Memoria cr√≠tico (default: 90%)

# Servicios monitoreados
monitor_backend_service      # Nombre servicio backend: "lti-backend"
monitor_frontend_service     # Nombre servicio frontend: "lti-frontend"
```

### Convenciones del Proyecto

- **Naming**: Mantiene convenci√≥n `lti-project-*` para consistencia
- **Tagging**: Tags espec√≠ficos para backend (`service:lti-backend`) y frontend (`service:lti-frontend`)
- **Estructura**: C√≥digo modular y documentado por funcionalidad

### Configuraci√≥n Inicial Requerida

Antes de continuar con los siguientes pasos, necesitas:

1. **Obtener credenciales de Datadog**:

   ```bash
   # Visita: https://app.datadoghq.com/organization-settings/api-keys
   # Obt√©n: API Key y Application Key
   ```

2. **Configurar variables**:

   ```bash
   cd tf/
   cp terraform.tfvars.example terraform.tfvars
   # Editar terraform.tfvars con tus credenciales reales
   ```

3. **Verificar configuraci√≥n**:
   ```bash
   terraform validate
   terraform plan
   ```

### Servicios AWS Monitoreados

- **EC2**: M√©tricas de instancias backend y frontend
- **CloudWatch**: Logs y m√©tricas del sistema
- **S3**: M√©tricas del bucket de c√≥digo
- **IAM**: Monitorizaci√≥n de roles y pol√≠ticas

### ‚úÖ Pasos Completados

#### Paso 1: Variables Terraform ‚úÖ

Se configuraron todas las variables necesarias en `tf/variables.tf` con validaciones de seguridad.

#### Paso 2: Proveedor Datadog ‚úÖ

Se configur√≥ el proveedor de Datadog v3.40+ en `tf/provider.tf` con autenticaci√≥n por API keys.

#### Paso 3: Integraci√≥n AWS-Datadog ‚úÖ

Se implement√≥ la integraci√≥n completa en `tf/datadog.tf` incluyendo:

- **Pol√≠tica IAM**: Permisos para CloudWatch, EC2, S3, IAM (solo lectura)
- **Role IAM**: Role con External ID que Datadog puede asumir
- **Dashboard**: Panel de control con m√©tricas de CPU y memoria
- **Outputs**: ARN del role, External ID y URLs para configuraci√≥n manual

**Configuraci√≥n Manual Requerida:**

1. En Datadog ‚Üí Integrations ‚Üí AWS ‚Üí Add AWS Account
2. Usar Role ARN: `(output de terraform apply)`
3. Usar External ID: `(output de terraform apply)`
4. Account ID: `(output de terraform apply)`

### Pr√≥ximos Pasos de Implementaci√≥n

- [ ] **Paso 4**: Instalar agentes Datadog en instancias EC2
- [ ] **Paso 5**: Configurar logs y APM espec√≠ficos del proyecto LTI
- [ ] **Paso 6**: Documentar configuraci√≥n final y verificar monitorizaci√≥n

### Comandos √ötiles

```bash
# Validar configuraci√≥n de Terraform
cd tf/
terraform validate

# Ver plan de despliegue
terraform plan

# Aplicar cambios (cuando est√© listo)
terraform apply

# Ver estado actual
terraform show
```

### Notas Importantes

‚ö†Ô∏è **Seguridad**:

- Las API keys de Datadog son **OBLIGATORIAS** y deben configurarse antes de continuar
- El External ID debe ser √∫nico y compartido solo con Datadog
- Nunca commit archivos `terraform.tfvars` con credenciales reales

üîß **Configuraci√≥n**:

- Los umbrales de alerta pueden ajustarse seg√∫n necesidades espec√≠ficas del LTI
- La configuraci√≥n actual soporta monitorizaci√≥n completa de la infraestructura AWS
- Tags espec√≠ficos permiten filtrado granular en Datadog

üìù **Documentaci√≥n**:

- Todos los cambios se documentan en `prompts/datadog-aws-prompts.md`
- Cada paso incluye verificaci√≥n y validaci√≥n
- Se mantiene historial de implementaci√≥n para referencia futura
